services:
  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    restart: unless-stopped
    networks:
      - monitoring
    volumes:
      - "{{ docker_mounts_directory }}/monitoring/influxdb:/var/lib/influxdb2"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 5s
      timeout: 10s
      retries: 20
    mem_limit: 100m

  scrutiny-web:
    image: ghcr.io/analogj/scrutiny:v0.8.1-web
    container_name: scrutiny-web
    restart: unless-stopped
    networks:
      - monitoring
      - web
    volumes:
      - /mnt/storage/scrutiny:/opt/scrutiny/config
    environment:
      SCRUTINY_WEB_INFLUXDB_HOST: influxdb
    depends_on:
      influxdb:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 5s
      timeout: 10s
      retries: 20
      start_period: 10s
    labels:
      - traefik.enable=true
      - traefik.docker.network=web
      # API traffic
      - traefik.http.routers.scrutiny-api.entryPoints=websecure
      - traefik.http.routers.scrutiny-api.rule=Host(`scrutiny.{{ ansible_fqdn }}`) && PathPrefix(`/api`)
      - traefik.http.routers.scrutiny-api.middlewares=lan-whitelist
      # Web traffic
      - traefik.http.routers.scrutiny-web.entryPoints=websecure
      - traefik.http.routers.scrutiny-web.rule=Host(`scrutiny.{{ ansible_fqdn }}`)
      - traefik.http.routers.scrutiny-web.middlewares=authelia@docker
    mem_limit: 32m

  prometheus:
    image: quay.io/prometheus/prometheus
    container_name: prometheus
    restart: unless-stopped
    networks:
      - monitoring
      - web
    command: >-
      --config.file=/etc/prometheus/prometheus.yml
      --storage.tsdb.path=/prometheus
      --web.console.libraries=/usr/share/prometheus/console_libraries
      --web.console.templates=/usr/share/prometheus/consoles
      --storage.tsdb.retention.time=1y
    volumes:
      - /mnt/storage/prometheus:/etc/prometheus
      - "{{ docker_mounts_directory }}/monitoring/prometheus:/prometheus"
    labels:
      - traefik.enable=true
      - traefik.docker.network=web
      - traefik.http.routers.prometheus.entryPoints=websecure
      - traefik.http.routers.prometheus.rule=Host(`prometheus.{{ ansible_fqdn }}`)
      - traefik.http.routers.prometheus.middlewares=authelia@docker
    mem_limit: 2g

  grafana:
    image: grafana/grafana-oss:11.1.0
    container_name: grafana
    restart: unless-stopped
    networks:
      - monitoring
      - web
    volumes:
      - "{{ docker_mounts_directory }}/grafana/data:/var/lib/grafana"
    labels:
      - traefik.enable=true
      - traefik.docker.network=web
      - traefik.http.routers.grafana.entryPoints=websecure
      - traefik.http.routers.grafana.rule=Host(`monitor.{{ ansible_fqdn }}`)
    environment:
      - GF_INSTALL_PLUGINS=volkovlabs-rss-datasource
      - GF_SERVER_ROOT_URL=https://monitor.{{ ansible_fqdn }}
      # SMTP
      - GF_SMTP_ENABLED=true
      - GF_SMTP_HOST={{ smtp__host }}:{{ smtp__port }}
      - GF_SMTP_USER={{ smtp__user }}
      - GF_SMTP_PASSWORD={{ smtp__pass | replace('$', '$$') }}
      - GF_SMTP_FROM_ADDRESS=grafana@{{ ansible_fqdn }}
      # OIDC
      - GF_AUTH_GENERIC_OAUTH_ENABLED=true
      - GF_AUTH_GENERIC_OAUTH_NAME=Authelia
      - GF_AUTH_GENERIC_OAUTH_CLIENT_ID={{ backbone__authelia__oidc_grafana_clientid }}
      - GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET={{ backbone__authelia__oidc_grafana_clientsecret }}
      - GF_AUTH_GENERIC_OAUTH_SCOPES=openid profile email groups
      - GF_AUTH_GENERIC_OAUTH_EMPTY_SCOPES=false
      - GF_AUTH_GENERIC_OAUTH_AUTH_URL=https://auth.{{ ansible_fqdn }}/api/oidc/authorization
      - GF_AUTH_GENERIC_OAUTH_TOKEN_URL=https://auth.{{ ansible_fqdn }}/api/oidc/token
      - GF_AUTH_GENERIC_OAUTH_API_URL=https://auth.{{ ansible_fqdn }}/api/oidc/userinfo
      - GF_AUTH_GENERIC_OAUTH_LOGIN_ATTRIBUTE_PATH=preferred_username
      - GF_AUTH_GENERIC_OAUTH_GROUPS_ATTRIBUTE_PATH=groups
      - GF_AUTH_GENERIC_OAUTH_NAME_ATTRIBUTE_PATH=name
      - GF_AUTH_GENERIC_OAUTH_USE_PKCE=true
      - GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_PATH=contains(groups, 'sysadmin') && 'GrafanaAdmin' || contains(groups, 'sysviewer') && 'Viewer'
      - GF_AUTH_GENERIC_OAUTH_ALLOW_ASSIGN_GRAFANA_ADMIN=true
      - GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_STRICT=true
    mem_limit: 256m

  loki:
    image: grafana/loki:3.1.0
    container_name: loki
    restart: unless-stopped
    volumes:
      - "{{ docker_mounts_directory }}/monitoring/loki:/loki"
    command: -config.file=/loki/loki-config.yaml
    networks:
      - monitoring
      - web
    labels:
      - traefik.enable=true
      - traefik.docker.network=web
      - traefik.http.routers.loki.entryPoints=websecure
      - traefik.http.routers.loki.rule=Host(`loki.{{ ansible_fqdn }}`)
      - traefik.http.routers.loki.middlewares=lan-whitelist
      - traefik.http.routers.loki.service=loki
      - traefik.http.services.loki.loadBalancer.server.port=3100
    mem_limit: 2g

  uptime:
    image: louislam/uptime-kuma:1
    container_name: uptime
    restart: unless-stopped
    networks:
      - monitoring
      - web
    volumes:
      - "{{ docker_mounts_directory }}/uptime:/app/data"
    labels:
      - traefik.enable=true
      - traefik.docker.network=web
      - traefik.http.routers.uptime.entryPoints=websecure
      - traefik.http.routers.uptime.rule=Host(`uptime.{{ ansible_fqdn }}`)
      - traefik.http.routers.uptime.middlewares=authelia@docker
    mem_limit: 128m

  plausible_clickhouse:
    image: clickhouse/clickhouse-server:24.6-alpine
    container_name: plausible_clickhouse
    restart: unless-stopped
    networks:
      - internal
    volumes:
      - "{{ docker_mounts_directory }}/plausible/clickhouse/data:/var/lib/clickhouse"
      - "{{ docker_mounts_directory }}/plausible/clickhouse/clickhouse-config.xml:/etc/clickhouse-server/config.d/logging.xml:ro"
      - "{{ docker_mounts_directory }}/plausible/clickhouse/clickhouse-user-config.xml:/etc/clickhouse-server/users.d/logging.xml:ro"
    # TODO: This is way too much mem, we should look into that
    mem_limit: 1g

  plausible:
    image: ghcr.io/plausible/community-edition:v2.1.1
    container_name: plausible
    restart: unless-stopped
    command: sh -c "sleep 10 && /entrypoint.sh db createdb && /entrypoint.sh db migrate && /entrypoint.sh run"
    networks:
      - internal
      - web
      - db
    depends_on:
      - plausible_clickhouse
    labels:
      - traefik.enable=true
      - traefik.docker.network=web
      - traefik.http.routers.plausible.entryPoints=websecure
      - traefik.http.routers.plausible.rule=Host(`plausible.{{ ansible_fqdn }}`)
      - traefik.http.routers.plausible.service=plausible
      - traefik.http.services.plausible.loadBalancer.server.port=8000
    environment:
      - DISABLE_REGISTRATION=true
      - SECRET_KEY_BASE={{ monitoring__plausible_secret }}
      - TOTP_VAULT_KEY={{ monitoring__plausible_totp_key }}
      - BASE_URL=https://plausible.{{ ansible_fqdn }}
      - DATABASE_URL=postgres://plausible:{{ monitoring__plausible__postgress_pass }}@postgres:5432/plausible
      - CLICKHOUSE_DATABASE_URL=http://plausible_clickhouse:8123/plausible_clickhouse
      - MAILER_EMAIL={{ smtp__from }}
      - SMTP_HOST_ADDR={{ smtp__host }}
      - SMTP_HOST_PORT={{ smtp__port }}
      - SMTP_USER_NAME={{ smtp__user }}
      - SMTP_USER_PWD={{ smtp__pass|replace('$','$$') }}
      - SMTP_HOST_SSL_ENABLED={{ smtp__tls }}
    mem_limit: 256m

  adguard_exporter:
    image: ebrianne/adguard-exporter:v1.14
    container_name: adguard_exporter
    restart: unless-stopped
    networks:
      - monitoring
    environment:
      - adguard_protocol=http
      - adguard_hostname={{ hostvars[groups['dns'][0]].ansible_host }}
      - adguard_username={{ monitoring__adguard_exporter_username }}
      - adguard_password={{ monitoring__adguard_exporter_password }}
      - server_port=9617
      - interval=10s
      - log_limit=10000
    mem_limit: 52m

networks:
  internal:
  monitoring:
    external: true
  web:
    external: true
  db:
    external: true
